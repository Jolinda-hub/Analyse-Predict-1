{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "91yHydRjEmqq"
   },
   "source": [
    "# Analyse : Predict\n",
    "\n",
    "Functions are important in reducing the replication of code as well as giving the user the functionality of getting an ouput on varying inputs. The functions you will write all use Eskom data/variables.\n",
    "\n",
    "For the predict, you will need to write 7 functions. These functions are:\n",
    "\n",
    "1. Metric Dictionary\n",
    "2. Five Number Summary Dictionary\n",
    "3. Date Parser\n",
    "4. Hashtag & Municipality Remover\n",
    "5. Number of Tweets per Day\n",
    "6. Word Splitter\n",
    "7. Stopwords & Link Remover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hmw-PmDMOPyQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS-1DpWNOUaR"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/electrification_by_province.csv'\n",
    "ebp = pd.read_csv(url)\n",
    "\n",
    "for col, row in ebp.iloc[:,1:].iteritems():\n",
    "    ebp[col] = ebp[col].str.replace(',','').astype(int)\n",
    "\n",
    "limpopo = ebp['Limpopo'].to_list()\n",
    "limpopo = [float(x) for x in limpopo]\n",
    "\n",
    "mpumalanga = ebp['Mpumalanga'].to_list()\n",
    "mpumalanga = [float(x) for x in mpumalanga]\n",
    "\n",
    "north_west = ebp['North west'].to_list()\n",
    "north_west = [float(x) for x in north_west]\n",
    "\n",
    "free_state = ebp['Free State'].to_list()\n",
    "free_state = [float(x) for x in free_state]\n",
    "\n",
    "kwazulu_natal = ebp['Kwazulu Natal'].to_list()\n",
    "kwazulu_natal = [float(x) for x in kwazulu_natal]\n",
    "\n",
    "eastern_cape = ebp['Eastern Cape'].to_list()\n",
    "eastern_cape = [float(x) for x in eastern_cape]\n",
    "\n",
    "western_cape = ebp['Western Cape'].to_list()\n",
    "western_cape = [float(x) for x in western_cape]\n",
    "\n",
    "northern_cape = ebp['Northern Cape'].to_list()\n",
    "northern_cape = [float(x) for x in northern_cape]\n",
    "\n",
    "gauteng = ebp['Gauteng'].to_list()\n",
    "gauteng = [float(x) for x in gauteng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zkUMnbVNOfu2"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/RidhaMoosa/eskom_data-/master/twitter_nov_2019.csv'\n",
    "twitter_df = pd.read_csv(url)\n",
    "\n",
    "dates = twitter_df['Date'].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQL8b34-HThO"
   },
   "source": [
    "# Function 1: Metric Dictionary\n",
    "\n",
    "Write a function which takes in a list of integers and returns a dictionary of the mean, median, variance, standard deviation, min and max. Answers should be rounded to the second decimal.\n",
    "\n",
    "_**Expected Output**_:\n",
    "\n",
    "```python\n",
    "gauteng = [39660.0,\n",
    "            36024.0,\n",
    "            32127.0,\n",
    "            39488.0,\n",
    "            18422.0,\n",
    "            23532.0,\n",
    "            8842.0,\n",
    "            37416.0,\n",
    "            16156.0,\n",
    "            18730.0,\n",
    "            19261.0,\n",
    "            25275.0]\n",
    "\n",
    "dictionary_of_metrics(gauteng) == {'mean': 26244.42,\n",
    "                                   'median': 24403.5,\n",
    "                                   'variance': 108160153.17,\n",
    "                                   'standard deviation': 10400.01,\n",
    "                                   'min': 8842.0,\n",
    "                                   'max': 39660.0}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauteng = [39660.0,\n",
    "            36024.0,\n",
    "            32127.0,\n",
    "            39488.0,\n",
    "            18422.0,\n",
    "            23532.0,\n",
    "            8842.0,\n",
    "            37416.0,\n",
    "            16156.0,\n",
    "            18730.0,\n",
    "            19261.0,\n",
    "            25275.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_of_metrics(items):\n",
    "    itemsort = sorted(items)\n",
    "    mean = np.mean(items)\n",
    "    variance = round(sum((i - mean) ** 2 for i in items) / (len(items)-1),2)\n",
    "    return {\"mean\": round(np.mean(items),2),\n",
    "            \"median\": np.median(items),\n",
    "            \"variance\": round(sum((i - mean) ** 2 for i in items) / (len(items)-1),2),\n",
    "            \"standard deviation\": round((int(variance) ** 0.5),2),\n",
    "            \"min\": itemsort[0],\n",
    "            \"max\": itemsort[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 26244.42,\n",
       " 'median': 24403.5,\n",
       " 'variance': 108160153.17,\n",
       " 'standard deviation': 10400.01,\n",
       " 'min': 8842.0,\n",
       " 'max': 39660.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_of_metrics(gauteng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-2fY34IHQwO"
   },
   "outputs": [],
   "source": [
    "def dictionary_of_metrics(items):\n",
    "    itemsort = sorted(items)\n",
    "    mean = np.mean(items)\n",
    "    variance = round(sum((i - mean) ** 2 for i in items) / (len(items)-1),2)\n",
    "    return {\"mean\": round(np.mean(items),2),\n",
    "            \"median\": np.median(items),\n",
    "            \"variance\": round(sum((i - mean) ** 2 for i in items) / (len(items)-1),2),\n",
    "            \"standard deviation\": round((int(variance) ** 0.5),2),\n",
    "            \"min\": itemsort[0],\n",
    "            \"max\": itemsort[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQIz0kjeJYYi"
   },
   "source": [
    "# Function 2: Five Number Summary\n",
    "\n",
    "Write a function which takes in a list of integers and returns a dictionary of the [five number summary.](https://www.statisticshowto.datasciencecentral.com/how-to-find-a-five-number-summary-in-statistics/) Answers should be rounded to the nearest second decimal.\n",
    "\n",
    "_**Expected Output:**_\n",
    "\n",
    "```python\n",
    "\n",
    "gauteng = [39660.0,\n",
    "            36024.0,\n",
    "            32127.0,\n",
    "            39488.0,\n",
    "            18422.0,\n",
    "            23532.0,\n",
    "            8842.0,\n",
    "            37416.0,\n",
    "            16156.0,\n",
    "            18730.0,\n",
    "            19261.0,\n",
    "            25275.0]\n",
    "\n",
    "five_num_summ(gauteng) == {'max': 39660.0,\n",
    "                           'median': 24403.5,\n",
    "                           'min': 8842.0,\n",
    "                           'q1': 18422.5,\n",
    "                           'q3': 36024.5}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max': 39660.0,\n",
       " 'median': 24403.5,\n",
       " 'min': 8842.0,\n",
       " 'q1': 18422.5,\n",
       " 'q3': 36024.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def five_num_summ(items):\n",
    "    sorteditems = sorted(items)\n",
    "    return {'max': sorteditems[-1],\n",
    "            'median': round(np.median(items),2) ,\n",
    "            'min': sorteditems[0],\n",
    "            'q1': np.percentile(sorteditems, 25, interpolation='lower') +.5,\n",
    "            'q3': np.percentile(sorteditems, 75, interpolation='lower') +.5}\n",
    "five_num_summ(gauteng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "eh = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "end = len(eh)/2\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(np.median(eh[:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.median(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZUUmnL1JWFr"
   },
   "outputs": [],
   "source": [
    "def five_num_summ(items):\n",
    "\n",
    "  ### Code Here\n",
    "\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETAOSB2oP9-Z"
   },
   "source": [
    "# Function 3: Date Parser\n",
    "\n",
    "Write a function which takes a list of datetime strings and converts it into a list of strings with only the date. \n",
    "<br>\n",
    "<br>\n",
    "_**Expected Output:**_\n",
    "\n",
    "```python\n",
    "\n",
    "dates = ['2019-11-29 12:50:54',\n",
    "         '2019-11-29 12:46:53',\n",
    "         '2019-11-29 12:46:10',\n",
    "         '2019-11-29 12:33:36',\n",
    "         '2019-11-29 12:17:43',\n",
    "         '2019-11-29 11:28:40']\n",
    "\n",
    "date_parser(dates) == ['2019-11-29',\n",
    "                       '2019-11-29',\n",
    "                       '2019-11-29',\n",
    "                       '2019-11-29',\n",
    "                       '2019-11-29',\n",
    "                       '2019-11-29']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2019-11-29 12:50:54',\n",
    "         '2019-11-29 12:46:53',\n",
    "         '2019-11-29 12:46:10',\n",
    "         '2019-11-29 12:33:36',\n",
    "         '2019-11-29 12:17:43',\n",
    "         '2019-11-29 11:28:40']\n",
    "def date_parser(list_dates):\n",
    "    return [i.split(' ', 1)[0] for i in list_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-11-29',\n",
       " '2019-11-29',\n",
       " '2019-11-29',\n",
       " '2019-11-29',\n",
       " '2019-11-29',\n",
       " '2019-11-29']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_parser(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IA0CkEJNW_J"
   },
   "outputs": [],
   "source": [
    "def date_parser(list_dates):\n",
    "    return [i.split(' ', 1)[0] for i in list_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W2GhFqo4SvD2"
   },
   "source": [
    "# Function 4: Municipality & Hashtag Remover\n",
    "\n",
    "Write a function which takes in a pandas dataframe and returns the same dataframe which is modified. The function should do the following:\n",
    "\n",
    "* Extract the municipality from a tweet using the dictonary given below into a new column in the same dataframe.\n",
    "* Extract the hashtag from a tweet into a new column in the same data frame.\n",
    "* The column headers should be \"municipality\" & \"hashtags\" respectively.\n",
    "* For those tweets which don't have the either a municipality nor a hashtag, fill it with ```np.nan```.\n",
    "\n",
    "Note: Only pandas and numpy packages may be used.\n",
    "\n",
    "```python\n",
    "\n",
    "municipality_dict = { '@CityofCTAlerts' : 'Cape Town',\n",
    "            '@CityPowerJhb' : 'Johannesburg',\n",
    "            '@eThekwiniM' : 'eThekwini' ,\n",
    "            '@EMMInfo' : 'Ekurhuleni',\n",
    "            '@centlecutility' : 'Mangaung',\n",
    "            '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "            '@CityTshwane' : 'Tshwane'}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErK3jHb5W8dE"
   },
   "source": [
    "_**Expected Outputs:**_ \n",
    "\n",
    "```python\n",
    "\n",
    "extract_municipality_hashtags(twitter_df).iloc[:11, :10]\n",
    "\n",
    "```\n",
    "![image](https://github.com/RidhaMoosa/eskom_data-/blob/master/function4.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_municipality_hashtags(df):\n",
    "    municipality_dict = { '@CityofCTAlerts' : 'Cape Town',\n",
    "            '@CityPowerJhb' : 'Johannesburg',\n",
    "            '@eThekwiniM' : 'eThekwini' ,\n",
    "            '@EMMInfo' : 'Ekurhuleni',\n",
    "            '@centlecutility' : 'Mangaung',\n",
    "            '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "            '@CityTshwane' : 'Tshwane'}\n",
    "    contains_email = []\n",
    "    hashtags = []\n",
    "    for x in df[\"Tweets\"]:\n",
    "        contains_email.append([municipality_dict[i] for i in x.split(' ') if i in municipality_dict.keys()])\n",
    "        hashtags.append([i for i in x.split(' ') if '#' in i])\n",
    "    contains_email_nan = [i if i else np.nan for i in contains_email]\n",
    "    hashtags_nan = [i if i else np.nan for i in hashtags]\n",
    "    df[\"municipality\"] = contains_email_nan\n",
    "    df[\"hashtags\"] = hashtags_nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>municipality</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@BongaDlulane Please send an email to mediades...</td>\n",
       "      <td>2019-11-29 12:50:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@saucy_mamiie Pls log a call on 0860037566</td>\n",
       "      <td>2019-11-29 12:46:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@BongaDlulane Query escalated to media desk.</td>\n",
       "      <td>2019-11-29 12:46:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Before leaving the office this afternoon, head...</td>\n",
       "      <td>2019-11-29 12:33:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...</td>\n",
       "      <td>2019-11-29 12:17:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[#ESKOMFREESTATE, #MEDIASTATEMENT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@IamGladstone @CityPowerJhb @HermanMashaba The...</td>\n",
       "      <td>2019-11-29 11:28:40</td>\n",
       "      <td>[Johannesburg]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @Exposcience: #FridayMotivation #EskomExpoI...</td>\n",
       "      <td>2019-11-29 11:27:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[#FridayMotivation, #EskomExpoISF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#EskomMpumalanga hosted a Supplier Development...</td>\n",
       "      <td>2019-11-29 11:07:18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[#EskomMpumalanga]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@maxon_hadebe @CityofJoburgZA Please log a cal...</td>\n",
       "      <td>2019-11-29 09:12:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Magudulela_M Hi,  Please log a call on MyEsko...</td>\n",
       "      <td>2019-11-29 09:08:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Exposcience: #FridayThoughts Norman Mashir...</td>\n",
       "      <td>2019-11-29 09:08:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[#FridayThoughts]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweets                 Date  \\\n",
       "0   @BongaDlulane Please send an email to mediades...  2019-11-29 12:50:54   \n",
       "1          @saucy_mamiie Pls log a call on 0860037566  2019-11-29 12:46:53   \n",
       "2        @BongaDlulane Query escalated to media desk.  2019-11-29 12:46:10   \n",
       "3   Before leaving the office this afternoon, head...  2019-11-29 12:33:36   \n",
       "4   #ESKOMFREESTATE #MEDIASTATEMENT : ESKOM SUSPEN...  2019-11-29 12:17:43   \n",
       "5   @IamGladstone @CityPowerJhb @HermanMashaba The...  2019-11-29 11:28:40   \n",
       "6   RT @Exposcience: #FridayMotivation #EskomExpoI...  2019-11-29 11:27:56   \n",
       "7   #EskomMpumalanga hosted a Supplier Development...  2019-11-29 11:07:18   \n",
       "8   @maxon_hadebe @CityofJoburgZA Please log a cal...  2019-11-29 09:12:47   \n",
       "9   @Magudulela_M Hi,  Please log a call on MyEsko...  2019-11-29 09:08:33   \n",
       "10  RT @Exposcience: #FridayThoughts Norman Mashir...  2019-11-29 09:08:12   \n",
       "\n",
       "      municipality                            hashtags  \n",
       "0              NaN                                 NaN  \n",
       "1              NaN                                 NaN  \n",
       "2              NaN                                 NaN  \n",
       "3              NaN                                 NaN  \n",
       "4              NaN  [#ESKOMFREESTATE, #MEDIASTATEMENT]  \n",
       "5   [Johannesburg]                                 NaN  \n",
       "6              NaN  [#FridayMotivation, #EskomExpoISF]  \n",
       "7              NaN                  [#EskomMpumalanga]  \n",
       "8              NaN                                 NaN  \n",
       "9              NaN                                 NaN  \n",
       "10             NaN                   [#FridayThoughts]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_municipality_hashtags(twitter_df).iloc[:11,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TEUIY_qCSYG"
   },
   "outputs": [],
   "source": [
    "def extract_municipality_hashtags(df):\n",
    "     municipality_dict = { '@CityofCTAlerts' : 'Cape Town',\n",
    "            '@CityPowerJhb' : 'Johannesburg',\n",
    "            '@eThekwiniM' : 'eThekwini' ,\n",
    "            '@EMMInfo' : 'Ekurhuleni',\n",
    "            '@centlecutility' : 'Mangaung',\n",
    "            '@NMBmunicipality' : 'Nelson Mandela Bay',\n",
    "            '@CityTshwane' : 'Tshwane'}\n",
    "    contains_email = []\n",
    "    hashtags = []\n",
    "    for x in df[\"Tweets\"]:\n",
    "        contains_email.append([municipality_dict[i] for i in x.split(' ') if i in municipality_dict.keys()])\n",
    "        hashtags.append([i for i in x.split(' ') if '#' in i])\n",
    "    contains_email_nan = [i if i else np.nan for i in contains_email]\n",
    "    hashtags_nan = [i if i else np.nan for i in hashtags]\n",
    "    df[\"municipality\"] = contains_email_nan\n",
    "    df[\"hashtags\"] = hashtags_nan\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uSuzSIc7_VUh"
   },
   "source": [
    "# Function 5: Number of Tweets per Day\n",
    "\n",
    "Write a function which calculates the number of tweets that were posted per day. \n",
    "\n",
    "This function should take in a pandas dataframe and return a new dataframe with columns \"```Date```\" & \"```Number of Tweets```\"\n",
    "\n",
    "Note: Only pandas and numpy may be used.\n",
    "\n",
    "_**Expected Output:**_\n",
    "\n",
    "```python\n",
    "\n",
    "number_of_tweets_per_day(twitter_df)\n",
    "\n",
    "```\n",
    "\n",
    "![function5](https://github.com/RidhaMoosa/eskom_data-/blob/master/function5.png?raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9Vo6QoAW6nm"
   },
   "outputs": [],
   "source": [
    "def number_of_tweets_per_day(df):\n",
    "\n",
    "  ### Code Here\n",
    "\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Wye_CrLFSgS"
   },
   "source": [
    "# Function 6: Word Splitter\n",
    "\n",
    "Write a function which splits a sentence into a list of the separate words. This is also known as [tokenization](https://www.geeksforgeeks.org/nlp-how-tokenizing-text-sentence-words-works/).\n",
    "\n",
    "The function should take in a dataframe and return a data with a new column \"```Split Tweets```\". Words should also all be lowercase.\n",
    "\n",
    "Note: Only pandas and numpy packages may be used.\n",
    "<br>\n",
    "<br>\n",
    "_**Expected Output**_:\n",
    "\n",
    "```python\n",
    "\n",
    "word_spliter(twitter_df) \n",
    "\n",
    "```\n",
    "\n",
    "![Function6](https://github.com/RidhaMoosa/eskom_data-/blob/master/Function6.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmEE1Zu7IrPu"
   },
   "outputs": [],
   "source": [
    "def word_spliter(df):\n",
    "\n",
    "  ### Code Here\n",
    "\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsCMKM0KKRsb"
   },
   "source": [
    "# Function 7: Stop Words & Link Remover\n",
    "\n",
    "Write a function which removes the stop words and the ur link from a tweet. The function should follow the criteria below:\n",
    "\n",
    "* Should remove stop words based on the dictionary provided below.\n",
    "* Should remove url's from the tweets. \n",
    "* The function will also need to tokenise thee sentence as indicated in function 6. Note: Function 6 may not be called within this function.\n",
    "* The column should be labelled as \"```Without Stop Words```\"\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "```python \n",
    "stop_words_dict = {'stopwords':['where', 'done', 'if', 'before', 'll', 'very', 'keep', 'something', 'nothing', 'thereupon', 'may', 'why', '’s', 'therefore', 'you', 'with', 'towards', 'make', 'really', 'few', 'former', 'during', 'mine', 'do', 'would', 'of', 'off', 'six', 'yourself', 'becoming', 'through', 'seeming', 'hence', 'us', 'anywhere', 'regarding', 'whole', 'down', 'seem', 'whereas', 'to', 'their', 'various', 'thereafter', '‘d', 'above', 'put', 'sometime', 'moreover', 'whoever', 'although', 'at', 'four', 'each', 'among', 'whatever', 'any', 'anyhow', 'herein', 'become', 'last', 'between', 'still', 'was', 'almost', 'twelve', 'used', 'who', 'go', 'not', 'enough', 'well', '’ve', 'might', 'see', 'whose', 'everywhere', 'yourselves', 'across', 'myself', 'further', 'did', 'then', 'is', 'except', 'up', 'take', 'became', 'however', 'many', 'thence', 'onto', '‘m', 'my', 'own', 'must', 'wherein', 'elsewhere', 'behind', 'becomes', 'alone', 'due', 'being', 'neither', 'a', 'over', 'beside', 'fifteen', 'meanwhile', 'upon', 'next', 'forty', 'what', 'less', 'and', 'please', 'toward', 'about', 'below', 'hereafter', 'whether', 'yet', 'nor', 'against', 'whereupon', 'top', 'first', 'three', 'show', 'per', 'five', 'two', 'ourselves', 'whenever', 'get', 'thereby', 'noone', 'had', 'now', 'everyone', 'everything', 'nowhere', 'ca', 'though', 'least', 'so', 'both', 'otherwise', 'whereby', 'unless', 'somewhere', 'give', 'formerly', '’d', 'under', 'while', 'empty', 'doing', 'besides', 'thus', 'this', 'anyone', 'its', 'after', 'bottom', 'call', 'n’t', 'name', 'even', 'eleven', 'by', 'from', 'when', 'or', 'anyway', 'how', 'the', 'all', 'much', 'another', 'since', 'hundred', 'serious', '‘ve', 'ever', 'out', 'full', 'themselves', 'been', 'in', \"'d\", 'wherever', 'part', 'someone', 'therein', 'can', 'seemed', 'hereby', 'others', \"'s\", \"'re\", 'most', 'one', \"n't\", 'into', 'some', 'will', 'these', 'twenty', 'here', 'as', 'nobody', 'also', 'along', 'than', 'anything', 'he', 'there', 'does', 'we', '’ll', 'latterly', 'are', 'ten', 'hers', 'should', 'they', '‘s', 'either', 'am', 'be', 'perhaps', '’re', 'only', 'namely', 'sixty', 'made', \"'m\", 'always', 'those', 'have', 'again', 'her', 'once', 'ours', 'herself', 'else', 'has', 'nine', 'more', 'sometimes', 'your', 'yours', 'that', 'around', 'his', 'indeed', 'mostly', 'cannot', '‘ll', 'too', 'seems', '’m', 'himself', 'latter', 'whither', 'amount', 'other', 'nevertheless', 'whom', 'for', 'somehow', 'beforehand', 'just', 'an', 'beyond', 'amongst', 'none', \"'ve\", 'say', 'via', 'but', 'often', 're', 'our', 'because', 'rather', 'using', 'without', 'throughout', 'on', 'she', 'never', 'eight', 'no', 'hereupon', 'them', 'whereafter', 'quite', 'which', 'move', 'thru', 'until', 'afterwards', 'fifty', 'i', 'itself', 'n‘t', 'him', 'could', 'front', 'within', '‘re', 'back', 'such', 'already', 'several', 'side', 'whence', 'me', 'same', 'were', 'it', 'every', 'third', 'together']}\n",
    "```\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "_**Expected Output**_:\n",
    "\n",
    "```python\n",
    "stop_words_http_remover(twitter_df)\n",
    "```\n",
    "\n",
    "![function7](https://github.com/RidhaMoosa/eskom_data-/blob/master/Function7.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7IHGYFtW5HJ"
   },
   "outputs": [],
   "source": [
    "def stop_words_http_remover(df):\n",
    "\n",
    "  # Code Here\n",
    "\n",
    "  pass"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Analyse_Functions_Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
